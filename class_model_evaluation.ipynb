{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- for final presentation, maybe mention development date for algorithms ? \n",
    "\n",
    "TODO:\n",
    "- update performance conclusion automatically\n",
    "- figure out inputing one \"row\" & predict ourcome (as if user info is predicted)\n",
    "- it works with features_test; but not with test_row  => figure out what type test_row needs to be\n",
    "- why is prediction accuracy 100% for some models? Not good (maybe fixed after manual prediction works?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carme\\AppData\\Local\\Temp\\ipykernel_23864\\2369937729.py:6: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(range(len(df)), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130327, 177)\n",
      "(32582, 177)\n",
      "(130327,)\n",
      "(32582,)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(df.columns[0],axis = 1)\n",
    "\n",
    "# remove colums containing NaN values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "df.set_axis(range(len(df)), inplace=True)\n",
    "\n",
    "# print(\"No. of columns containing null values\")\n",
    "# print(len(df.columns[df.isna().any()]))\n",
    "\n",
    "# print(\"No. of columns not containing null values\")\n",
    "# print(len(df.columns[df.notna().all()]))\n",
    "\n",
    "# print(\"Total no. of columns in the dataframe\")\n",
    "# print(len(df.columns))s\n",
    "\n",
    "# removing target('diabetes') from features\n",
    "target = df['diabetes']\n",
    "features = df.drop(['diabetes'],axis=1)\n",
    "\n",
    "# splitting into training and test data\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(features_train.shape)\n",
    "# print(features_test.shape)\n",
    "# print(target_train.shape)\n",
    "# print(target_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29                                                     \n",
      "Accuracy : 96.01313608741022                           \n",
      "13                                                                                \n",
      "Accuracy : 94.12252163771407                                                      \n",
      "91                                                                                \n",
      "Accuracy : 99.2050825609232                                                       \n",
      "53                                                                                \n",
      "Accuracy : 98.38254250813333                                                      \n",
      "88                                                                                \n",
      "Accuracy : 99.0424160579461                                                       \n",
      "98                                                                                \n",
      "  5%|▌         | 5/100 [00:28<09:10,  5.80s/trial, best loss: -0.9920508256092321]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m svm_accuracy , \u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: STATUS_OK }\n\u001b[0;32m     21\u001b[0m trials \u001b[39m=\u001b[39m Trials()\n\u001b[1;32m---> 22\u001b[0m best \u001b[39m=\u001b[39m fmin(cost_function,\n\u001b[0;32m     23\u001b[0m     space \u001b[39m=\u001b[39;49m SEARCH_SPACE,\n\u001b[0;32m     24\u001b[0m     algo \u001b[39m=\u001b[39;49m tpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[0;32m     25\u001b[0m     max_evals \u001b[39m=\u001b[39;49m MAX_EVALS, \n\u001b[0;32m     26\u001b[0m     trials \u001b[39m=\u001b[39;49m trials)\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(best)\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mcost_function\u001b[1;34m(max_iter)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m max_iter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m svm_classifier \u001b[39m=\u001b[39m make_pipeline(StandardScaler(), svm\u001b[39m.\u001b[39;49mSVC(max_iter\u001b[39m=\u001b[39;49mmax_iter))\u001b[39m.\u001b[39;49mfit(features_train, target_train)\n\u001b[0;32m     14\u001b[0m \u001b[39m# svm_classifier = svm.SVC(kernel = \"linear\", max_iter = max_iter)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m svm_predictions \u001b[39m=\u001b[39m svm_classifier\u001b[39m.\u001b[39mpredict(features_test)\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    253\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    332\u001b[0m     X,\n\u001b[0;32m    333\u001b[0m     y,\n\u001b[0;32m    334\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    335\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    336\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    337\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[0;32m    338\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    339\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    340\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    341\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    342\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    343\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    344\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    345\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    346\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    347\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    348\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    349\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    350\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optimizing max_iter to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 100\n",
    "SEARCH_SPACE = [hp.randint('max_iter',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_iter):\n",
    "    max_iter = max_iter[0]\n",
    "    print(max_iter)\n",
    "    if max_iter == 0:\n",
    "        return 0\n",
    "    svm_classifier = make_pipeline(StandardScaler(), svm.SVC(max_iter=max_iter)).fit(features_train, target_train)\n",
    "    # svm_classifier = svm.SVC(kernel = \"linear\", max_iter = max_iter)\n",
    "    svm_predictions = svm_classifier.predict(features_test)\n",
    "    svm_accuracy = accuracy_score(target_test, svm_predictions)\n",
    "\n",
    "    print(f\"Accuracy : {100 * svm_accuracy}\")\n",
    "    return {'loss': - svm_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' with previously determined max_iter #################################################################################################\n",
    "\n",
    "# see distribution of 1 & 0 on test data\n",
    "print(Counter(target_test))\n",
    "\n",
    "# change to automatically get best max_iter & fill in here! TODO\n",
    "max_iter = 32\n",
    "svm_classifier = make_pipeline(StandardScaler(), svm.SVC(max_iter=max_iter)).fit(features_train, target_train)\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(svm_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = svm_classifier.predict(test_row)\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(svm_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)\n",
    "\n",
    "# bzw: what type of input needs test_row to be?!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "\n",
    "- simple SVM: Best reachable Accuracy: 86.80559 %, with max_iter= 36\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy: 99.66852863544289%, with max_iter = 93"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Stocastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52                                                    \n",
      "Accuracy : 99.99693082069855                          \n",
      "89                                                                               \n",
      "Accuracy : 99.98772328279418                                                     \n",
      "33                                                                               \n",
      "Accuracy : 99.99386164139709                                                     \n",
      "44                                                                               \n",
      "Accuracy : 100.0                                                                 \n",
      "15                                                                               \n",
      "Accuracy : 99.98465410349272                                      \n",
      "32                                                                \n",
      "Accuracy : 100.0                                                  \n",
      "80                                                                \n",
      "Accuracy : 100.0                                                  \n",
      "91                                                                \n",
      "Accuracy : 99.99693082069855                                      \n",
      "52                                                                \n",
      "Accuracy : 99.99386164139709                                      \n",
      "2                                                                 \n",
      "Accuracy : 99.77288073169235                                      \n",
      "100%|██████████| 10/10 [00:08<00:00,  1.12trial/s, best loss: -1.0]\n",
      "{'max_iter': 44}\n"
     ]
    }
   ],
   "source": [
    "# Optimizing max_iter to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 10\n",
    "SEARCH_SPACE = [hp.randint('max_iter',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_iter):\n",
    "    max_iter = max_iter[0]\n",
    "    if max_iter == 0:\n",
    "        return 0\n",
    "    print(max_iter)\n",
    "    sgd_classifier = make_pipeline(StandardScaler(), SGDClassifier(max_iter=max_iter)).fit(features_train, target_train)\n",
    "    #sgd_classifier = SGDClassifier(max_iter = max_iter).fit(features_train, target_train)\n",
    "    sgd_predictions = sgd_classifier.predict(features_test)\n",
    "    sgd_accuracy = accuracy_score(target_test, sgd_predictions)\n",
    "\n",
    "    print(f\"Accuracy : {100 * sgd_accuracy}\")\n",
    "    return {'loss': - sgd_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predicting for one specific 'person' with previously determined max_iter #################################################################################################\n",
    "\n",
    "# see distribution od 1 & 0 on test data\n",
    "# print(Counter(target_test))\n",
    "\n",
    "# change to automatically get best max_iter & fill in here! TODO\n",
    "max_iter = 3\n",
    "sgd_classifier = SGDClassifier(max_iter = max_iter).fit(features_train, target_train)\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(sgd_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index]\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = sgd_classifier.predict([test_row])\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(sgd_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)\n",
    "\n",
    "# bzw: what type of input needs test_row to be?!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- simple SGD: Best reachable Accuracy:  87.33042784359463%, with max_iter= 74\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy:  100%, with max_iter = 11 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Stocastic Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing max_depth to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 100\n",
    "SEARCH_SPACE = [hp.randint('max_depth',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_depth):\n",
    "    max_depth = max_depth[0]\n",
    "    if max_depth == 0:\n",
    "        return 0\n",
    "    print(max_depth)\n",
    "    # sgb_classifier = make_pipeline(StandardScaler(), sgb_classifier = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=max_depth, random_stat=0).fit(features_train, target_train)\n",
    "    sgb_classifier = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=max_depth).fit(features_train, target_train)    \n",
    "    sgb_predictions = sgb_classifier.predict(features_test)\n",
    "    sgb_accuracy = accuracy_score(target_test, sgb_predictions)\n",
    "    comp = target_test == sgb_predictions\n",
    "    print(Counter(comp))\n",
    "    print(f\"Accuracy : {100 * sgb_accuracy}\")\n",
    "    return {'loss': - sgb_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' with previously determined max_iter #################################################################################################\n",
    "\n",
    "# see distribution od 1 & 0 on test data\n",
    "print(Counter(target_test))\n",
    "\n",
    "# change to automatically get best max_iter & fill in here! TODO\n",
    "max_depth = 32\n",
    "sgb_classifier = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=max_depth).fit(features_train, target_train)    \n",
    "\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(sgb_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = sgb_classifier.predict(test_row)\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(sgb_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)\n",
    "\n",
    "# bzw: what type of input needs test_row to be?!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- simple SGB: Best reachable Accuracy:  87.33042784359463%, with max_iter= 74\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy:  100%, with max_iter = 11 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f891c0ef62455f9f8d0cbb2d117bcba51effc94d210f58e83104cbf88b6bc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
